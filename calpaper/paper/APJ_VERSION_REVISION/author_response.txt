We thank the referee for the thorough review of our paper and software. In addition to addressing the referee's comments, we have made some additional code changes since the paper was initially submitted submitted (v1.27.1), and the most recent version which is available at the time that these revisions are being submitted (v1.27.2). Of particular note, these code changes produced NO CHANGES to the calibration results presented in the paper at the precision used. We address each of the referee's points below. A summary of substantive changes made to the software to version 1.27.2 is provided at the bottom of this reply.

--------------------------------------------------------------------------------
RESPONSES TO EDITOR COMMENTS
--------------------------------------------------------------------------------
In addition to these comments, I just wanted to mention that while it's great that you have provided scripts to reproduce the plots in the paper, I would like to ask you to avoid including a Python pickle file, since these have no guarantee of working in the long term. Please use archival formats instead, whether plain text, JSON, FITS, HDF5, or other similar formats.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: The data that were previously contained in the pickle files have been added as columns of other CSV files that shared the same row definitions. The figures.py scripts have been updated to reflect this change.
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
RESPONSES TO REFEREE COMMENTS
--------------------------------------------------------------------------------

Abstract
--------

"photon event" - This term may need a specific definition (are there other event types? Are there photons that are not events?). For the abstract I suggest to use the simple term "photon", leaving the exact definition for the text.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have simplified the abstract to refer to "photons" instead of "photon events," and in the Motivation section we describe more precisely what we mean by "events" generally as distinct from "photons" or "photon events."
--------------------------------------------------------------------------------

Which version of the software does this describe? I understand that software evolves and articles do not, but the tests described here are done with one specific version e.g. when the authors say "summarize photometric and astrometric performance ...", those metrics might be version dependent.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: The revised paper refers to v1.27.2 of the code, which will be merged to master and available on PyPI at the time that we are submitting these revisions. The code version is recorded in the __init__.py, which is propagated to pip. We have added the version that this paper describes in the last paragraph of Section 1, and the last sentence of the Abstract.
--------------------------------------------------------------------------------

The word "python" turns up a couple of times. In some places it is capitalized, in others it is not. According to the PSF (Python software foundation) "the name of our favourite programming language is always capitalized" (https://pl.python.org/docs/doc/style-guide.html).
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have standardized capitalization of the use of "Python" throughout.
--------------------------------------------------------------------------------


Sect 1
-------
I'm missing a few more introductory sentences about "photon events".
This is common in x-ray and gammy-ray astronomy, but even UV astronmers traditionally think about integrated quantities, fluxes etc.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have added sentences in the second paragraph of Section 1 describing what the MCPs record, and how those data are reduced (to RA, DEC, time stamps, and fluxes) at a very high level. This is in addition to the description in Section 2 where we talk a bit more about what causes events (i.e. not necessarily astrophysical photons).
--------------------------------------------------------------------------------


Sect 4
-------
Where individual tools are described, the reader would profit from a simple example for each of them that shows an examplary call on the command line or in the python interpreter (the documentation of all parameters an be left for the user manual).
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have added very basic examples of how to run three of the four main commands in Table 2 to their descriptions within that table. The fourth command -- gPipeline, which we note will be of minimal interest to most users -- requires additional, local data products to work properly; a description of what those are, how to obtain them, and how to run gPipeline is provided in the User Guide, so the table directs readers to that resource.
--------------------------------------------------------------------------------

The gPhoton project defines timestamps in units of "GALEX time" throughout, where GALEX time is defined as a linear offset from UNIX or POSIX time, where tGALEX = tUNIX âˆ’ 315964800 seconds.
However, UNIX time does not handle leap seconds properly. Two leap seconds occured during the GALEX mission. How is this dealt with?
--------------------------------------------------------------------------------
AUTHOR RESPONSE: Like UNIX time on which it is based, GALEX time does not handle leap seconds. Users requiring this level of precision will need to apply a correction. We've added a note on this issue to the User Guide. As a convenience, we do include a few time conversion methods in "gphoton_utils", which take GALEX time as input and returns JD_TDB, JD_UTC, JD_TAI, or a calendar date (in UTC). These methods make use of the astropy.Time module, so the precision in converting between time standards and accounting for leap seconds is limited by the precision inherit to AstroPy's implementations. gPhoton also does not currently adjust times to barycenter, which can be a much larger effect than two leap seconds; we plan to add barycentric correction in the future, but another note has been added to the User Guide in the meantime.
--------------------------------------------------------------------------------

The gPhoton software is described in several places as a dabase of individual photons. However, after reading this manuscript, the User Guide, and installing and playing around with the software, it is still unclear to me which steps allow the user to retrieve a full calibrated photon list. (gAperture only retunred binned quantities. gPipeline is supposed to return a photon list, but unlike the other tools it requires a raw6 and scst file as input. Where would I get those? Why can they not be downloaded automatically with the skypos and time as in gAperture?)
--------------------------------------------------------------------------------
AUTHOR RESPONSE: The photon (events) are returned under the 'photons' key in the dictionary data structure that is returned by gAperture when run as a module.  (For example, if you set the return of gAperture to a variable: `x = gAperture(...)`, the events would be stored in `x['photons']`.) Prompted by this note, we have also added a gAperture option (in v1.27.2) to save the unbinned photon events as a CSV file (with, e.g., `photoncsvfile=<...>`) when called from _either_ the command line or as a module.
--------------------------------------------------------------------------------

gPipeline: Do photon list files contain the values for the weighting factors for flat and dead time correction that are applied by gMap or gAperture tools? In other words, do the photon lists contain all the informnation needed for the analysis in some form or are the later tools required to download/calculate more information?
The authors put an emphasis on the fact that single-photon retrievel is possible, so this point should be mentioned.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: The output of gPipeline (the photon list files) do not contain calibration values such as this. However, the photon lists returned by gAperture contain all information needed, including the flat values. We have added more description in the document describing the single-photon retrieval capabilities.
--------------------------------------------------------------------------------

In the high-energy community (X-ray, gammay ray), astronomers work almost exclusivley with single event data and methods and software packages exisit for e.g. source detection, or lightcurve analysis (e.g. Baysian block algorithm) that do not bin events, but treat individual events to calcualte likelyhoods. Those users would profit from having as much information as possible availalbe without the need to consult tools that bin the data into images or lightcurves.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: When used as an imported module, the data structure returned by gAperture includes the unbinned data. We have also added the option to save photon events to a CSV file when running in command-line mode as well (via the "photoncsvfile" option). We have also updated the UserGuide entry in gAperture to emphasize these features.
--------------------------------------------------------------------------------

Sect 5
-------
In Sect 5.2 the authors suggest that the difference in the background they see compared to the MCAT is due to sources in the background annulus and they suggest that software users manually identify contaminating sources in the images. They should try out this suggestion for a few cases and report the differene between the MCAT background and that measured from an annulus placed by hand to avoid contaminating sources, since this is what they recommend users to do.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: For 549 'NUV' sources with a delta-magnitude of >0.2 and AB magnitude >22 when using the Annulus background method, we have confirmed by visual inspection (using gMap) that a large fraction of these have a relatively bright nearby star (i.e. within the outer annulus) that would contaminate the background estimate and could be avoided with a more judicious selection of annulus extent. Rather than manually define new apertures for all ~500 sources, we reran gAperture for these sources with a smaller aperture of extending [0.005,0.001] (degrees) from the source position. Without except, this resulted in background corrected magnitudes closer to zero, with a median offset of 0.156 from the previous value (with the larger annulus) towards zero.
--------------------------------------------------------------------------------

In Fig 6, there seems to be a systematic trend, such that all exposures > 150 s produce values above the expected magnitude. Is there a known reason?
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We do not know of a reason, nor did anyone on the mission team who we asked. It doesn't appear to be an issue for "normal" (non-calibration survey) data. We consider the fact that gPhoton reproduces this apparent systematic to be evidence of our successful reproduction of the mission calibration pipeline at the visit level (since this trend is present in the mission-produced MCAT itself, and reproduced in a "blind" sense by our software, as we hadn't granted much attention to the trend until it was pointed out here).
--------------------------------------------------------------------------------

The last few sentences of Sect 5.4 suggest to filter on leg. Are there instructions for users how this can be done?
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have added a description on how to filter on leg in the UserGuide.  We would prefer not to put that description in the paper because the exact method may change. (The current method is rather slow; we have a plan for making it very fast, but it will require generating a new table in the database. The condition of "FUV + CAI + legs 1,2,3" will also get a flag value in the light curve files, until such time as we might fix the issue completely.) We added a note to Section 5.4, to consult the User Guide for how to filter on leg.
--------------------------------------------------------------------------------

Sect 6
-------
6.3 Relative response correction: The authors describe that the original version of the pipeline used several interpolations to calcualte the appropriate response for each pixel on the detector. In contrast, the new software avoids that.
One common reason for interpolating response maps is that the original flat-field data is noisy and has to be smoothed by interpolation. Did the authors verify that that is not a problem in this case?
--------------------------------------------------------------------------------
AUTHOR RESPONSE: Flat-field noise can be a problem, but is generally restricted to the detector edges where the response is less well characterized. Indeed, this is one of several reasons we caution the user to avoid the edges (and by default, many of the gPhoton routines to do so automatically). Short time-domain light curves of sources that stay within the linear response regime of the detector and near the center of the field-of-view have not shown strong correlations with detector position in any of our analyses.
--------------------------------------------------------------------------------

Sect 6.4 hotpsots: The authors acknowledge that overlooking that a source moved through a hot spot can lead to spourios time variability. I strongly encourge them to ensure that their software alerts a user to this condition e.g. by means of a warning or by returning nan values in the lightcurves or images.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: Version 1.27.2 flags for hotspots quite conservatively, so following the general advice to avoid any binned fluxes with non-zero flags will greatly reduce this problem. Our team has analyzed short time domain light curves of several thousands sources for significant variability since this change and found no instances of unflagged false positives due to hotspot masking. Future software versions will attempt to improve the hotspot flagging to avoid rejecting too many valid events. Yet still, our experience has taught us that one should _never_ trust the light curve without visually inspecting the corresponding gMap movie images.
--------------------------------------------------------------------------------

Sect 7
------
Since this is meant as a usage example, I suggest to give the main commands that where used verbatim. There is no need to show all the plot code (I agree with the authors that makes a good attachement as a separate file), but as a reader I probably want to see an example of how to call the relevant modules at this point.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have added a brief paragraph showing how we made use of gFind, gMap, and gAperture to create the CR Draconis light curves (2nd paragraph in Section 7 now). In that paragraph we include the calls to gFind, gMap, and gAperture (examples are used when imported as modules, command-line would be almost the same).
--------------------------------------------------------------------------------

Fig 12, caption:
"such points can be identified by a flag" - I suggest giving the name of the flag here.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We've added the specific bit to check in the flag bitmask to the figure caption (bit 4 is the one for nonlinearity warning). The bitmask look-up table is also in the UserGuide.
--------------------------------------------------------------------------------

Fig 13:
I understand that this analysis is merely a usage example, but it should be correct and well readable.
In this respect Fig 13 is lacking. What are the coordiantes on the x and y axis? What is the color scaling? Why is the background annulus (i) so close to CR Dra that is is visibly dominated by the wings of CR Dra's PSF? Why is it so small (since there are fewer counts in the background than in the source, I would expect that you chose a large background region. Otherwise the error on the CR Dra flux will be dominated by the counting statistics in the small background aperture)?
--------------------------------------------------------------------------------
AUTHOR RESPONSE: xxxxxxxxxx Pending. (Scott)
--------------------------------------------------------------------------------

Figures
-------
There is no need to group figures and tables at the end of the manuscript any longer. ApJ/AJ used to have such a policy, but ended it many years ago and at least this referee finds it preferrable to place them in the text close to the position where they are discussed.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have moved tables and figures to be placed near where they are first referenced in the manuscript.  We will produce a 2-column version using the "emulateapj" package before posting to the arXiv preprint server, upon paper acceptance.
--------------------------------------------------------------------------------

Figures look a little blurred. I can referee them fine, but I encourange the authors to make use of a vector graphics format such as pdf for most of their plots.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We were unable to reproduce this issue, but we now use PDF versions of the figures instead of EPS.
--------------------------------------------------------------------------------


Software on github
===================

Installation
------------
Manually modifying the PYTHONPATH is not the best practice solution because it might interfere with e.g. virtualenv, conda environments etc. The de-facto standard is using setuptools, where the names of relevant command line scripts are defined as "entry points".
--------------------------------------------------------------------------------
AUTHOR RESPONSE:
--------------------------------------------------------------------------------

Installations instructions Ubuntu: Note that you can get astropy through "apt-get" as well.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: Noted, and a comment was added to the User Guide.
--------------------------------------------------------------------------------

When trying out the software I followed the instruction in docs/UserGuide.md and that did not work. pip installing into Anaconda will not activate the command line scripts (see note about "entry points" above). I strongly encourage the authors to fix this - incomplete installation instructions are probably the fasted way to turn a user to look elsewhere.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We were unfortunately not able to reproduce this issue with the information provided. In a normal bug report situation, we would ask for additional information, but the anonymous nature of the review makes that difficult.
--------------------------------------------------------------------------------

Calling from within the Python interpreter
------------------------------------------
This is a little more cumbersome than it has to be.
This is the current interface:

>>> import gPhoton
>>> import gPhoton.gFind
>>> gPhoton.gFind(skypos=[123, 23])
>>> import gPhoton.gAperture
>>> gPhoton.gAperture.gAperture(skypos=[123, 34])

would the following not feel more natural?

>>> import gPhoton
>>> gPhoton.gfind(skypos=[123,34])
>>> ...

this can easyly be done by simple edits of __init__.py
to include lines like:
from gFind import gFine as gfind
from gAperture import gAperture as gaperture
...
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have decided to take this opportunity to clean up this behavior, although we've retained the intercap (because we like it, and it matches the command-line syntax). Imports now work as follows, e.g.:

        import gPhoton
        gPhoton.gFind(skypos=[10,20])
--------------------------------------------------------------------------------


Python version
--------------
The code is obviously written for python 2 and will fail on Python 3. It's probably not too hard to convert using 2to3 or six, but it should state somewhere which Python versions are supported and which versions of numpy, scipy, astropy, ... are tested and known to work.
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We plan to make gPhoton compatible with Python 3.x in addition to Python 2.7.x in the near future. For now, the software has only been tested on Python 2.7.x. We have added a note about this in the UserGuide.
--------------------------------------------------------------------------------


Some comments on the code
=========================
I do not think that it is on the referee of the manuscript to also provide a complete code review for gPhoton. On the other hand, this paper is "just" the published reference that the autors presumably intend to be the standard reference to using that code; there is not a whole lot of science to review in the paper.
Thus, I did browse through some of the modules on github (commit 6c83159) to gain an impression if, as a science user, I would trust this code of if it's design raises any alarming flags with me.
(I have to admit, that I was tempted to open PRs for some of the issues, but that would clearly give away my name - and I generally leave it up to the editor to decide if the referee should remain anonymous.)

The points listed below are to a certain degree just issues of style, thus my comments should be treated a suggestions, not as "the referee required us to make this change".

Use of Python features
----------------------
While things work the way they are written, the authors could have made use of some more build-in python capabilities, for example:

gPhoton/gPipeline.py
Most of what function check_args does is to check is arguments are present - this can be enforced by using the "required" keyword argument in "parser.add_argument" or to convert stuff to strings (again, the argparser can do that already).
--------------------------------------------------------------------------------
AUTHOR RESPONSE: As far as we understand, the argparse module only gets used when the tools are called from the command line. check_args() is programmed in this way to enforce some minimal requirements when the tools are imported as modules, since we want to enable both use cases.
--------------------------------------------------------------------------------

Readability counts
------------------
In some cases, the code could be simplified (but all the following code is untested):

gPhoton/PhotonPipe.py - line 301-316 can probably be reduced to 4 lines of code:

cut_fptrx = np.array(fptrx[ix], dtype='int64')
cut_fptry = np.array(fptry[ix], dtype='int64')

cut[ix] = (np.any(walk_x[q[ix], cut_fptry: cut_fptry + 2, cut_fptrx: cut_fptrx + 2] != -999) |
np.any(walk_y[q[ix], cut_fptry: cut_fptry + 2, cut_fptrx: cut_fptrx + 2] != -999))

(a similar desing pattern is seen in line 276 of the same file and the idea to define
cut_fptrx = np.array(fptrx[ix], dtype='int64')
cut_fptry = np.array(fptry[ix], dtype='int64')
so that this does not have to be repeated in every line applies to other code blocks as well, e.g. line 380).
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We agree that this would be a clarifying simplification, but don't want to change this particular module at this time because it is the heart of the software that produced the values now recorded in the database (gPipeline). We're planning an upcoming modification to the database (to restore data covered by the hotspot mask), which will involve changes to this module and extensive retesting; we will make clarity revisions of PhotonPipe.py at that time.
--------------------------------------------------------------------------------

Docs
----
The authors have written all docstrings in a format that sphinx will read. Are the rendered API docs available somewhere (e.g. readthedocs or on github pages)?
--------------------------------------------------------------------------------
AUTHOR RESPONSE: We have added API documentation using sphinx autodoc and hosted on readthedocs.  A link to the readthedocs API is now available on the main page in GitHub.
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
SUMMARY OF CHANGES BETWEEN SOFTWARE BRANCH v1.27.1 (on submission) and v1.27.2 (will be merged upon acceptance).
--------------------------------------------------------------------------------

We have rerun our full suite of regression tests (including regenerating all graphics), which include the astrometry, relative photometry, and absolute photometry presented in the paper, and have found minimal difference between the two branches in terms of the results presented in the paper. Software changes that might potentially have resulted in substantive calibration changes (but did not!) include the following.

1.) We have slightly modified the method of computing the "MCAT" background for a target. It still does exactly what is described in the paper, but it should do a better job of selecting the closest MCAT visit (in time and space) from which to draw a background estimate. The text (and User Guide) has been modified to describe the new feature that in rare cases that no appropriate visit is found, the MCAT estimated background is set to NaN. Note that the calibration results have not changed at the level of precision that they are reported in the paper. This is not unexpected because the change should really only effect cases where there is no nearby MCAT source; the calibration tests uses only locations of known MCAT sources and so avoid this case by construction.

2.) We took the opportunity of rerunning the calibration to make the baseline sample 10,000 in both bands to better permit direct comparison (which is less in NUV and more in FUV than was used before). We have modified the description of the manuscript (and figures) accordingly. Note that, despite the change in sample size, the calibration results have not changed at the level of precision that they are reported in the paper.

For a complete history of changes since the initial paper submission, please see the list of Github issues under the v1.27.2 milestone and commit log starting from 6/2/2016 through the merge of branch v1.27.2 into Master.
